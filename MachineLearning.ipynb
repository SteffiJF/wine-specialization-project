{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineLearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOb21YeaEUlLej8WRELx2a0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SteffiJF/wine-specialization-project/blob/main/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkwCoYjXWYAd"
      },
      "source": [
        "Constructing features and targets and running LSTM models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sCh0OO8P7H2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a9b5eb-5bf0-4619-9458-6303741e1b9b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials\t\n",
        "from datetime import datetime\n",
        "%matplotlib inline\n",
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import keras.backend as K\n",
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "import seaborn as sns\n",
        "import matplotlib._color_data as mcd\n",
        "# Use seaborn style defaults and set the default figure size\n",
        "sns.set(rc={'figure.figsize':(10, 6)})\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey-9uAZCqdMP"
      },
      "source": [
        "Loading data from Google Disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsq0wWUZjNEO"
      },
      "source": [
        "#Settting up connection to Google Disk\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#Loading district sales data\n",
        "download = drive.CreateFile({'id': '1TQiphmTgnwQCpPsuOJDEPL59UwXU18Kv'})\n",
        "download.GetContentFile('aggData')\n",
        "df = pd.read_csv(\"aggData\")\n",
        "\n",
        "#Loading wine sales data\n",
        "download = drive.CreateFile({'id': '1_EI5mruMITjXloABXYyo5BGMo-mEzpj1'})\n",
        "download.GetContentFile('topWines')\n",
        "dfW = pd.read_csv(\"topWines\")\n",
        "\n",
        "#Loading baseline analysis\n",
        "download = drive.CreateFile({'id': '14OvekNaapSeGIt8HTM9KqCj7XYqjpShz'})\n",
        "download.GetContentFile('SarimaY')\n",
        "dfSY = pd.read_csv(\"SarimaY\")\n",
        "\n",
        "download = drive.CreateFile({'id': '1pW-eKW_zNqPVB82CCKufDWro8cRXbNof'}) \n",
        "download.GetContentFile('SarimaY2')\n",
        "dfSY2 = pd.read_csv(\"SarimaY2\")\n",
        "\n",
        "download = drive.CreateFile({'id': '1f-3XyHPP-gtlRFHHkTENcKl_If8C7Mt2'}) \n",
        "download.GetContentFile('SarimaY3')\n",
        "dfSY3 = pd.read_csv(\"SarimaY3\")\n",
        "\n",
        "#Removing old index\n",
        "dfW = dfW.drop('Unnamed: 0', axis=1)\n",
        "dfSY = dfSY.drop('Unnamed: 0', axis=1)\n",
        "dfSY2 = dfSY2.drop('Unnamed: 0', axis=1)\n",
        "dfSY3 = dfSY3.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "#Setting index to yyyy-mm-dd\n",
        "df['År_Måned'] = pd.to_datetime(df['År_Måned'])\n",
        "df = df.set_index('År_Måned')\n",
        "dfW['År_Måned'] = pd.to_datetime(dfW['År_Måned'])\n",
        "dfW = dfW.set_index(['Artikkelnr','År_Måned']).sort_index()\n",
        "\n",
        "#Removing areas that did not pass visual inspection of plots\n",
        "\n",
        "#List of areas\n",
        "areas = df.columns\n",
        "#print(areas)\n",
        "#Returns string with area name from index\n",
        "def area_name(i):\n",
        "  return areas[i]\n",
        "\n",
        "#Makes a list of area names that will be removed\n",
        "def areas_to_remove(removeUncertainAreas = True):\n",
        "  badAreaIndex = [0,1,3,9,10,14,19,25,28,29,37,40,53,64,68,69]#[0,3,9,10,14,19,25,28,29,37,40,53,64,69]\n",
        "  uncertainAreaIndex = [1,11,15,17,22,30,34,43,44,66,71]#fjernet 68 og la til over\n",
        "  badAreas = []\n",
        "  for i in badAreaIndex:\n",
        "    badAreas.append(area_name(i))\n",
        "  if removeUncertainAreas == True:\n",
        "    for i in uncertainAreaIndex:\n",
        "      badAreas.append(area_name(i))\n",
        "  return badAreas\n",
        "\n",
        "badAreas = areas_to_remove(removeUncertainAreas=False)\n",
        "\n",
        "for area in badAreas:\n",
        "  df.drop(area, axis=1, inplace=True)\n",
        "\n",
        "df.to_csv('final_agg_data.csv',sep=';')\n",
        "\n",
        "#Updated list of areas\n",
        "areas = df.columns\n",
        "#print(len(areas))\n",
        "\n",
        "#print(areas)\n",
        "val_areas = areas\n",
        "\n",
        "#Updating columns names\n",
        "dfSY.columns = areas\n",
        "dfSY2.columns = areas\n",
        "dfSY3.columns = areas\n",
        "\n",
        "#Updating index names\n",
        "dfSY.index = df.index\n",
        "dfSY2.index = df.index\n",
        "dfSY3.index = df.index"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DSO1J4Pqpe7"
      },
      "source": [
        "Constructing different features for aggregated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIoy5qq3kYx9"
      },
      "source": [
        "#Features for X-values\n",
        "\n",
        "#Differencing with lag 12\n",
        "dfDiff = df.diff(periods=12)\n",
        "\n",
        "#Percentwice differencing with lag 12\n",
        "dfPctDiff = df.pct_change(periods=12)\n",
        "\n",
        "#Soft clamping dfPctDiff to avoid large peaks\n",
        "dfSoftPctDiff = np.arcsinh(dfPctDiff)\n",
        "\n",
        "#Dividing differenced data by shifted rolling standard deviation \n",
        "dfStdDiff = dfDiff/dfDiff.shift(1).rolling(12).std()\n",
        "dfStdPctDiff = dfPctDiff/dfPctDiff.shift(1).rolling(12).std()\n",
        "dfStdSoftPctDiff = dfSoftPctDiff/dfSoftPctDiff.shift(1).rolling(12).std()\n",
        "\n",
        "#Finding positive and negative spikes \n",
        "#dfSpikes = dfStdDiff.apply(lambda x: [1 if y >= 3 else (-1 if y<=-3 else 0) for y in x])\n",
        "dfSpikes = dfStdPctDiff.apply(lambda x: [1 if y >= 3 else (-1 if y<=-3 else 0) for y in x])\n",
        "#dfSmallSpikes = dfStdDiff.apply(lambda x: [1 if y >= 2 else (-1 if y<=-2 else 0) for y in x])\n",
        "\n",
        "\n",
        "#Finding the rolling mean of spikes (testing width 3, can reconsider width later).\n",
        "#These are not shifted, meaning that the sum for a row is the sum of that row and the two previous rows\n",
        "dfSpikes = dfSpikes.rolling(3).sum()\n",
        "\n",
        "#Creating categories 1,0, and -1 depending on the majority of spikes\n",
        "dfSpikes = dfSpikes.apply(lambda x: [1 if y > 0 else (-1 if y < 0 else 0) for y in x])\n",
        "\n",
        "#Replacing inf with 0 where necessary\n",
        "df = df.replace([np.inf, -np.inf], 0)\n",
        "dfDiff = dfDiff.replace([np.inf, -np.inf], 0)\n",
        "dfPctDiff = dfPctDiff.replace([np.inf, -np.inf], 0)\n",
        "dfSoftPctDiff = dfSoftPctDiff.replace([np.inf, -np.inf], 0)\n",
        "dfStdDiff = dfStdDiff.replace([np.inf, -np.inf], 0)\n",
        "dfStdPctDiff = dfStdPctDiff.replace([np.inf, -np.inf], 0)\n",
        "dfStdSoftPctDiff = dfStdPctDiff.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "#Removing nan values\n",
        "df = df.fillna(0)\n",
        "dfDiff = dfDiff.fillna(0)\n",
        "dfPctDiff = dfPctDiff.fillna(0)\n",
        "dfSoftPctDiff = dfSoftPctDiff.fillna(0)\n",
        "dfStdDiff = dfStdDiff.fillna(0)\n",
        "dfStdPctDiff = dfStdPctDiff.fillna(0)\n",
        "dfStdSoftPctDiff = dfStdSoftPctDiff.fillna(0)\n",
        "\n",
        "\n",
        "#Setting up Y-values\n",
        "\n",
        "\n",
        "#First classification, checks percentage-wise difference of coming year's sum vs previous year's sum\n",
        "dfY = df.rolling(12).sum().shift(-12)\n",
        "dfY = dfY.pct_change(periods=12)\n",
        "dfY= dfY.apply(lambda x: [2 if y >= 0.3 else (0 if y<=-0.3 else 1) for y in x])\n",
        "\n",
        "#Second calssification, checks the mean of the coming years difference divided by standard deviation\n",
        "dfY2 = dfStdDiff.rolling(12).mean().shift(-12)\n",
        "dfY2 = dfY2.apply(lambda x: [2 if y >= 1 else (0 if y<=-1 else 1) for y in x])\n",
        "\n",
        "#Third classification, checks the amount of small positive spikes in the percentage-wise change divided by standard deviation\n",
        "dfSmallSpikes2 = dfStdPctDiff.apply(lambda x: [1 if y >= 2 else (-1 if y<=-2 else 0) for y in x])\n",
        "dfY3 = dfSmallSpikes2.rolling(12).sum().shift(-12)\n",
        "dfY3 = dfY3.apply(lambda x: [2 if y >= 3 else (0 if y<=-3 else 1) for y in x])\n",
        "\n",
        "\n",
        "#Removing nan values, set to 1 which is neutral\n",
        "dfY = dfY.fillna(1)\n",
        "dfY2 = dfY2.fillna(1)\n",
        "dfY3 = dfY3.fillna(1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GkewcZKqOV-"
      },
      "source": [
        "Top 5 wines for each district"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htRF8V58Y6v-"
      },
      "source": [
        "#Extracting article numbers from dataframe\n",
        "articles = dfW.index.values.tolist()\n",
        "articles = [row[0] for row in articles]\n",
        "articles = list(dict.fromkeys(articles))\n",
        "\n",
        "\n",
        "#Finding an arbitrary article with 154 rows and adding to empty dataframe\n",
        "def set_df_length(df, oldArticles):\n",
        "  for art in articles:\n",
        "    if len(dfW.loc[art].index.values)==154:\n",
        "      df[art] = dfW.loc[art]['Liter']\n",
        "      oldArticles = oldArticles + [art]\n",
        "      return df, oldArticles\n",
        "\n",
        "#List for storing articles already added to dataframe \n",
        "oldArticles = []\n",
        "\n",
        "#Dataframe for storing all of the liters sold with article nr as columne name\n",
        "dfWL = pd.DataFrame()\n",
        "\n",
        "#Adding a first column to the dataframe to assure correct length\n",
        "dfWL, oldArticles = set_df_length(dfWL, oldArticles)\n",
        "\n",
        "#Dataframe for storing which articles come from which area\n",
        "dfAA = pd.DataFrame()\n",
        "\n",
        "#Looping through all of the areas and adding data to dfWL and dfAA\n",
        "for area in areas:\n",
        "  dfTemp=dfW[dfW['Område']==area]\n",
        "  if not dfTemp.empty:\n",
        "    articles = dfTemp.index.values.tolist()\n",
        "    articles = [row[0] for row in articles]\n",
        "    articles = list(dict.fromkeys(articles))\n",
        "    if len(articles)==5:\n",
        "      dfAA[area] = articles\n",
        "      #print(articles)\n",
        "      for i in range(0,5):\n",
        "        #Avoiding adding duplicated wines twice\n",
        "        if articles[i] not in oldArticles:\n",
        "          #print(articles[i])\n",
        "          dfWL[articles[i]] = dfTemp.loc[articles[i]]['Liter']\n",
        "      oldArticles = oldArticles + articles\n",
        "      #print(oldArticles)\n",
        "\n",
        "\n",
        "\n",
        "#Replacing NaN with 0.\n",
        "dfWL = dfWL.fillna(0)\n",
        "\n",
        "\n",
        "x = dfWL.values #returns a numpy array\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "dfWL = pd.DataFrame(x_scaled, columns= dfWL.columns)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bJa7YPPwyZw"
      },
      "source": [
        "Calculating results of ARIMA baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgpKxWHEtyvC",
        "outputId": "b95ffa2d-9575-498f-e62f-0511adaf898a"
      },
      "source": [
        "#Initializing lists and fnuctions\r\n",
        "listY=[]\r\n",
        "listSY=[]\r\n",
        "listY2=[]\r\n",
        "listSY2=[]\r\n",
        "listY3=[]\r\n",
        "listSY3=[]\r\n",
        "precisionS=np.zeros(3)\r\n",
        "precisionS2=np.zeros(3) \r\n",
        "precisionS3=np.zeros(3)\r\n",
        "\r\n",
        "def precision(label, confusion_matrix):\r\n",
        "    col = confusion_matrix[:, label]\r\n",
        "    return confusion_matrix[label, label] / col.sum()\r\n",
        "\r\n",
        "\r\n",
        "#Gathering test values for all districts in lists\r\n",
        "for i in range(len(areas)):\r\n",
        "  listY = np.append(listY, dfY[areas[i]][122:141])\r\n",
        "  listSY = np.append(listSY, dfSY[areas[i]][122:141])\r\n",
        "  listY2 = np.append(listY2, dfY2[areas[i]][122:141])\r\n",
        "  listSY2 = np.append(listSY2, dfSY2[areas[i]][122:141])\r\n",
        "  listY3 = np.append(listY3, dfY3[areas[i]][122:141])\r\n",
        "  listSY3 = np.append(listSY3, dfSY3[areas[i]][122:141])\r\n",
        "\r\n",
        "#Comparing ARIMA results to true values\r\n",
        "\r\n",
        "#Y\r\n",
        "precisionsS=precision_recall_fscore_support(listY, listSY, beta=1.0, labels=None, average='macro')[0]\r\n",
        "recallS=precision_recall_fscore_support(listY, listSY, beta=1.0, labels=None, average='macro')[1]\r\n",
        "f1scoreS=precision_recall_fscore_support(listY, listSY, beta=1.0, labels=None, average='macro')[2]\r\n",
        "micro_f1scoreS = precision_recall_fscore_support(listY, listSY, beta=1.0, labels=None, average='micro')[2]\r\n",
        "\r\n",
        "\r\n",
        "#Y2\r\n",
        "precisionsS2=precision_recall_fscore_support(listY2, listSY2, beta=1.0, labels=None, average='macro')[0]\r\n",
        "recallS2=precision_recall_fscore_support(listY2, listSY2, beta=1.0, labels=None, average='macro')[1]\r\n",
        "f1scoreS2=precision_recall_fscore_support(listY2, listSY2, beta=1.0, labels=None, average='macro')[2]\r\n",
        "micro_f1scoreS2 = precision_recall_fscore_support(listY2, listSY2, beta=1.0, labels=None, average='micro')[2]\r\n",
        "\r\n",
        "\r\n",
        "#Y3\r\n",
        "precisionsS3=precision_recall_fscore_support(listY3, listSY3, beta=1.0, labels=None, average='macro')[0]\r\n",
        "recallS3=precision_recall_fscore_support(listY3, listSY3, beta=1.0, labels=None, average='macro')[1]\r\n",
        "f1scoreS3=precision_recall_fscore_support(listY3, listSY3, beta=1.0, labels=None, average='macro')[2]\r\n",
        "micro_f1scoreS3 = precision_recall_fscore_support(listY3, listSY3, beta=1.0, labels=None, average='micro')[2]\r\n",
        "\r\n",
        "\r\n",
        "#Closer precision analysis\r\n",
        "cmS = confusion_matrix(listY, listSY, labels=[0, 1, 2])\r\n",
        "cmS2 = confusion_matrix(listY2, listSY2, labels=[0, 1, 2])\r\n",
        "cmS3 = confusion_matrix(listY3, listSY3, labels=[0, 1, 2])\r\n",
        "\r\n",
        "for i in range(0,3):\r\n",
        "  precisionS[i]=precision(i, cmS)\r\n",
        "  precisionS2[i]=precision(i, cmS2)  \r\n",
        "  precisionS3[i]=precision(i, cmS3)\r\n",
        "\r\n",
        "#Printing results\r\n",
        "print('Y')\r\n",
        "print(precisionsS,recallS,f1scoreS,micro_f1scoreS)\r\n",
        "print(precisionS)\r\n",
        "\r\n",
        "print('Y2')\r\n",
        "print(precisionsS2,recallS2,f1scoreS2,micro_f1scoreS2)\r\n",
        "print(precisionS2)\r\n",
        "\r\n",
        "print('Y3')\r\n",
        "print(precisionsS3,recallS3,f1scoreS3,micro_f1scoreS3)\r\n",
        "print(precisionS3)\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y\n",
            "0.49873677111799103 0.4210257428071568 0.39155414389251847 0.6889097744360902\n",
            "[0.42857143 0.75220264 0.31543624]\n",
            "Y2\n",
            "0.3034410667425464 0.38664834076356475 0.3250116509251346 0.49530075187969924\n",
            "[0.07692308 0.57090012 0.2625    ]\n",
            "Y3\n",
            "0.4716619981325863 0.3500527092557453 0.29088556396922416 0.5366541353383458\n",
            "[0.7        0.57773109 0.1372549 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_N3rGTKYgYl"
      },
      "source": [
        "Preparing data for machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYtniGv-NCYQ",
        "outputId": "29e1e9e6-66d3-4190-b5b0-4ab5b6028050"
      },
      "source": [
        "#Constructing train and test data\n",
        "\n",
        "n_steps = 15\n",
        "\n",
        "nr_sets = len(df)-26-12-(n_steps-1) #26 for beginning, 12 at end, 14 for extra months\n",
        "nr_test_months = round(nr_sets*0.2)\n",
        "nr_train_months = round((nr_sets-nr_test_months)*0.8)\n",
        "\n",
        "\n",
        "start_train_months = 26 \n",
        "end_train_months= start_train_months+nr_train_months+ n_steps-1\n",
        "end_test_months = len(df)-13 #1 for index and 12 for months without y-values \n",
        "start_test_months = end_test_months - nr_test_months-n_steps+2 \n",
        "\n",
        "start_val_months = end_train_months-n_steps+2+6 #+6 for quarantine period between train and validation\n",
        "end_val_months = start_test_months + n_steps-1\n",
        "\n",
        "areas = dfAA.columns  \n",
        "\n",
        "#Scaling data\n",
        "\n",
        "def scale(df):\n",
        "  x = df.values \n",
        "  min_max_scaler = MinMaxScaler()\n",
        "  x_scaled = min_max_scaler.fit_transform(x)\n",
        "  #robust_scaler = RobustScaler()\n",
        "  #x_scaled = robust_scaler.fit_transform(x)\n",
        "  return pd.DataFrame(x_scaled, columns= df.columns)\n",
        "\n",
        "\n",
        "\n",
        "dfS = scale(df)\n",
        "dfDiffS = scale(dfDiff)\n",
        "dfPctDiffS = scale(dfPctDiff)\n",
        "dfSoftPctDiffS = scale(dfSoftPctDiff)\n",
        "dfStdDiffS = scale(dfStdDiff)\n",
        "dfStdPctDiffS = scale(dfStdPctDiff)\n",
        "dfStdSoftPctDiffS = scale(dfStdSoftPctDiff)\n",
        "dfSpikesS = scale(dfSpikes)\n",
        "dfWLS = scale(dfWL) \n",
        "\n",
        "\n",
        "#Function from Jason Brownlee\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "\n",
        "#Shapes features correctly for specified months and splits the sequences \n",
        "def shape_data(i,start_months, end_months):\n",
        "\n",
        "  x1=array(dfS[areas[i]][start_months:end_months])\n",
        "  x2=array(dfDiffS[areas[i]][start_months:end_months])\n",
        "  x3=array(dfPctDiffS[areas[i]][start_months:end_months])\n",
        "  x4=array(dfSoftPctDiffS[areas[i]][start_months:end_months])\n",
        "  x5=array(dfStdDiffS[areas[i]][start_months:end_months])\n",
        "  x6=array(dfStdPctDiffS[areas[i]][start_months:end_months])\n",
        "  x7=array(dfStdSoftPctDiffS[areas[i]][start_months:end_months])\n",
        "  x8=array(dfSpikesS[areas[i]][start_months:end_months])\n",
        "  \n",
        "  #Top wine sales\n",
        "  x9=array(dfWLS[dfAA[areas[i]][0]][start_months:end_months])\n",
        "  x10=array(dfWLS[dfAA[areas[i]][1]][start_months:end_months])\n",
        "  x11=array(dfWLS[dfAA[areas[i]][2]][start_months:end_months])\n",
        "  x12=array(dfWLS[dfAA[areas[i]][3]][start_months:end_months])\n",
        "  x13=array(dfWLS[dfAA[areas[i]][4]][start_months:end_months])\n",
        "  \n",
        "  y=array(dfY[areas[i]][start_months:end_months])\n",
        "\n",
        "  x1=x1.reshape((len(x1),1))\n",
        "  x2=x2.reshape((len(x2),1))\n",
        "  x3=x3.reshape((len(x3),1))\n",
        "  x4=x4.reshape((len(x4),1))\n",
        "  x5=x5.reshape((len(x5),1))\n",
        "  x6=x6.reshape((len(x6),1))\n",
        "  x7=x7.reshape((len(x7),1))\n",
        "  x8=x8.reshape((len(x8),1))\n",
        "  x9=x9.reshape((len(x9),1))\n",
        "  x10=x10.reshape((len(x10),1))\n",
        "  x11=x11.reshape((len(x11),1))\n",
        "  x12=x12.reshape((len(x12),1))\n",
        "  x13=x13.reshape((len(x13),1))\n",
        "  y=y.reshape((len(y),1))\n",
        "\n",
        "  #Change this to decide which features to use\n",
        "  dataset = hstack(( x1, x2, x3, x4, x5, x6, x7, x9, y)) \n",
        "\n",
        "  return split_sequences(dataset, n_steps)\n",
        "\n",
        "\n",
        "#Making the training data\n",
        "\n",
        "X,y = shape_data(0,start_train_months,end_train_months)\n",
        "\n",
        "for i in range(1,len(areas)):\n",
        "  Xnew, ynew = shape_data(i,start_train_months,end_train_months)\n",
        "  #Appending sequences together\n",
        "  X = np.vstack((X,Xnew))\n",
        "  y = np.append(y,ynew)\n",
        "\n",
        "\n",
        "#Making the validation data\n",
        "\n",
        "Xval,yval = shape_data(0,start_val_months,end_val_months)\n",
        "\n",
        "for i in range(1,len(areas)):\n",
        "  Xnew, ynew = shape_data(i,start_val_months,end_val_months)\n",
        "  #Appending sequences together\n",
        "  Xval = np.vstack((Xval,Xnew))\n",
        "  yval = np.append(yval,ynew)\n",
        "\n",
        "\n",
        "#Making the test data\n",
        "\n",
        "Xtest,ytest = shape_data(0,start_test_months,end_test_months)\n",
        "\n",
        "for i in range(1,len(areas)):\n",
        "  Xnew, ynew = shape_data(i,start_test_months,end_test_months)\n",
        "  #print(i,len(ynew))\n",
        "  #Appending sequences together\n",
        "  Xtest = np.vstack((Xtest,Xnew))\n",
        "  ytest = np.append(ytest,ynew)\n",
        "\n",
        "print('Before resampling')\n",
        "print(sorted(Counter(y).items()))\n",
        "print(sorted(Counter(yval).items()))\n",
        "print(sorted(Counter(ytest).items()))\n",
        "\n",
        "\n",
        "#Balancing the dataset by using random sampler on indices instead of X, as X \n",
        "#has 3D instead of 2D which is the limit\n",
        "\n",
        "#Train\n",
        "\n",
        "indices = np.arange(y.shape[0]).reshape(-1,1)\n",
        "\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "indexResampled, y = ros.fit_resample(indices, y)\n",
        "\n",
        "#Loops through the repeated indices, as these are placed after the original values\n",
        "for i in range(len(indices), len(indexResampled)):\n",
        "  #Appends 2D arrays from X to X by identifying them with index from indexResampled\n",
        "  #The X[sample] is reshaped to have the same shape as X\n",
        "  X = np.append(X,X[indexResampled[i]].reshape(1,X.shape[1],X.shape[2]), axis=0)\n",
        "\n",
        "\n",
        "def resampler(X,y):\n",
        "  indices = np.arange(y.shape[0]).reshape(-1,1)\n",
        "\n",
        "  ros = RandomOverSampler(random_state=0)\n",
        "  indexResampled, y = ros.fit_resample(indices, y)\n",
        "\n",
        "  #Loops through the repeated indices, as these are placed after the original values\n",
        "  for i in range(len(indices), len(indexResampled)):\n",
        "    #Appends 2D arrays from X to X by identifying them with index from indexResampled\n",
        "    #The X[sample] is reshaped to have the same shape as X\n",
        "    X = np.append(X,X[indexResampled[i]].reshape(1,X.shape[1],X.shape[2]), axis=0)\n",
        "  \n",
        "  return X,y\n",
        "\n",
        "X,y = resampler(X,y)\n",
        "\n",
        "\n",
        "#Shuffling the input the same way for X and y\n",
        "\n",
        "#New list of indices with additional samples\n",
        "indices = np.arange(y.shape[0])\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "y= y.astype(int)\n",
        "yval = yval.astype(int)\n",
        "ytest = ytest.astype(int)\n",
        "\n",
        "\n",
        "print('After resampling')\n",
        "print(sorted(Counter(y).items()))\n",
        "print(sorted(Counter(yval).items()))\n",
        "print(sorted(Counter(ytest).items()))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before resampling\n",
            "[(0.0, 590), (1.0, 2573), (2.0, 533)]\n",
            "[(0.0, 55), (1.0, 367), (2.0, 82)]\n",
            "[(0.0, 189), (1.0, 711), (2.0, 164)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After resampling\n",
            "[(0, 2573), (1, 2573), (2, 2573)]\n",
            "[(0, 55), (1, 367), (2, 82)]\n",
            "[(0, 189), (1, 711), (2, 164)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKMttxTTanoH"
      },
      "source": [
        "LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkEOdvqnhiLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238487ba-09fd-4cec-e51c-9a9bfb102957"
      },
      "source": [
        "#Importing learning rate finder, used for finding optimal learning rate\n",
        "#https://github.com/surmenok/keras_lr_finder\n",
        "\n",
        "#src = list(files.upload().values())[0]\n",
        "#open('lr_finder.py','wb').write(src)\n",
        "#import lr_finder\n",
        "#from lr_finder import LRFinder\n",
        "\n",
        "\n",
        "#Multivariate LSTM model for categorical prediction\n",
        "\n",
        "n_features = X.shape[2]\n",
        "n_outputs = 3\n",
        "runs = 10 \n",
        "\n",
        "#Preparation for analysis\n",
        "accuracies = np.zeros(runs)\n",
        "precisions = np.zeros(runs)\n",
        "recalls = np.zeros(runs)\n",
        "f1scores = np.zeros(runs)\n",
        "micro_f1scores = np.zeros(runs)\n",
        "precision0 = np.zeros(runs)\n",
        "precision1 = np.zeros(runs)\n",
        "precision2 = np.zeros(runs)\n",
        "\n",
        "\n",
        "#Code from https://www.python-course.eu/confusion_matrix.php\n",
        "\n",
        "def precision(label, confusion_matrix):\n",
        "    col = confusion_matrix[:, label]\n",
        "    return confusion_matrix[label, label] / col.sum()\n",
        "    \n",
        "def recall(label, confusion_matrix):\n",
        "    row = confusion_matrix[label, :]\n",
        "    return confusion_matrix[label, label] / row.sum()\n",
        "\n",
        "def precision_macro_average(confusion_matrix):\n",
        "    rows, columns = confusion_matrix.shape\n",
        "    sum_of_precisions = 0\n",
        "    for label in range(rows):\n",
        "        sum_of_precisions += precision(label, confusion_matrix)\n",
        "    return sum_of_precisions / rows\n",
        "\n",
        "def recall_macro_average(confusion_matrix):\n",
        "    rows, columns = confusion_matrix.shape\n",
        "    sum_of_recalls = 0\n",
        "    for label in range(columns):\n",
        "        sum_of_recalls += recall(label, confusion_matrix)\n",
        "    return sum_of_recalls / columns\n",
        "\n",
        "\n",
        "#Defining model\n",
        "\n",
        "for i in range(runs):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features))) \n",
        "  model.add(Dense(n_outputs))\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=0.0001) #Default lr is 0.001\n",
        "  model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "  #Used to find optimal learning rate\n",
        "  #lr_finder = LRFinder(model)\n",
        "  #lr_finder.find(X, y, 0.00001, 1, 32, 23)\n",
        "  #lr_finder.plot_loss()\n",
        "\n",
        "\n",
        "  #Fitting model\n",
        "  history = model.fit(X, y, validation_data =(Xval, yval), batch_size=32, epochs=20, verbose=1)\n",
        "\n",
        "  #Used to find optimal epochs\n",
        "  #from keras import callbacks \n",
        "  #earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",  \n",
        "  #                                        mode =\"min\", patience = 5,  \n",
        "  #                                        restore_best_weights = True) \n",
        "    \n",
        "  #history = model.fit(X, y,   \n",
        "  #                    epochs = 100, batch_size=32, validation_data = (Xval, yval),  \n",
        "  #                    callbacks =[earlystopping]) #fjernet batch size\n",
        "\n",
        "\n",
        "\n",
        "  #Evaluating model\n",
        "  _, accuracy = model.evaluate(Xtest, ytest, verbose=0)\n",
        "  print(i)\n",
        "\n",
        "  prediction = np.argmax(model.predict(Xtest), axis=-1)\n",
        "  cm = confusion_matrix(ytest, prediction, labels=[0, 1, 2])\n",
        "\n",
        "  label=[0,1,2]\n",
        "  print(\"label precision recall\")\n",
        "  for label in range(3):\n",
        "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n",
        "\n",
        "  print('Accuracy: %.2f' % (accuracy*100))\n",
        "  print(\"precision total:\", precision_macro_average(cm))\n",
        "  print(\"recall total:\", recall_macro_average(cm))\n",
        "\n",
        "  \n",
        "  accuracies[i]=accuracy\n",
        "  precisions[i]=precision_recall_fscore_support(ytest, prediction, beta=1.0, labels=None, average='macro')[0]\n",
        "  recalls[i]=precision_recall_fscore_support(ytest, prediction, beta=1.0, labels=None, average='macro')[1]\n",
        "  f1scores[i]=precision_recall_fscore_support(ytest, prediction, beta=1.0, labels=None, average='macro')[2]\n",
        "  micro_f1scores[i] = precision_recall_fscore_support(ytest, prediction, beta=1.0, labels=None, average='micro')[2]\n",
        "\n",
        "  precision0[i]=precision(0, cm)\n",
        "  precision1[i]=precision(1, cm)  \n",
        "  precision2[i]=precision(2, cm)\n",
        "\n",
        "print('')\n",
        "print('Accuracies:', np.average(accuracies))\n",
        "#print(accuracies)\n",
        "\n",
        "print('Precisions:', np.average(precisions))\n",
        "#print(precisions)\n",
        "\n",
        "print('Recalls:', np.average(recalls))\n",
        "#print(recalls)\n",
        "\n",
        "print('F1-scores:', np.average(f1scores), 'std:', np.std(f1scores))\n",
        "\n",
        "print('F1-scores micro:', np.average(micro_f1scores), 'std:', np.std(micro_f1scores))\n",
        "\n",
        "print('Precision class 0:', np.average(precision0))\n",
        "#print(precision0)\n",
        "\n",
        "print('Precision class 1:', np.average(precision1))\n",
        "#print(precision1)\n",
        "\n",
        "print('Precision class 2:', np.average(precision2))\n",
        "#print(precision2)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 9ms/step - loss: 1.0787 - accuracy: 0.4313 - val_loss: 0.9574 - val_accuracy: 0.6131\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0076 - accuracy: 0.4978 - val_loss: 0.9327 - val_accuracy: 0.5694\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9186 - accuracy: 0.5925 - val_loss: 0.9467 - val_accuracy: 0.6329\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8871 - accuracy: 0.6133 - val_loss: 0.8368 - val_accuracy: 0.6687\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8575 - accuracy: 0.6295 - val_loss: 0.8874 - val_accuracy: 0.6508\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8283 - accuracy: 0.6445 - val_loss: 0.8356 - val_accuracy: 0.6687\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7985 - accuracy: 0.6609 - val_loss: 0.8520 - val_accuracy: 0.6567\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7839 - accuracy: 0.6795 - val_loss: 0.9298 - val_accuracy: 0.6508\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7600 - accuracy: 0.6866 - val_loss: 0.9424 - val_accuracy: 0.6409\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7321 - accuracy: 0.6998 - val_loss: 0.8767 - val_accuracy: 0.6706\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7083 - accuracy: 0.7053 - val_loss: 0.7749 - val_accuracy: 0.6944\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7176 - accuracy: 0.6985 - val_loss: 0.8270 - val_accuracy: 0.6806\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6993 - accuracy: 0.6990 - val_loss: 0.9114 - val_accuracy: 0.6389\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6819 - accuracy: 0.7160 - val_loss: 0.8192 - val_accuracy: 0.6865\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6585 - accuracy: 0.7278 - val_loss: 0.8592 - val_accuracy: 0.6766\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6505 - accuracy: 0.7253 - val_loss: 0.8458 - val_accuracy: 0.6944\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6435 - accuracy: 0.7356 - val_loss: 0.8965 - val_accuracy: 0.6766\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6353 - accuracy: 0.7365 - val_loss: 0.9810 - val_accuracy: 0.6806\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6091 - accuracy: 0.7504 - val_loss: 0.9468 - val_accuracy: 0.6687\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6103 - accuracy: 0.7503 - val_loss: 0.9694 - val_accuracy: 0.6706\n",
            "0\n",
            "label precision recall\n",
            "    0     0.347  0.566\n",
            "    1     0.854  0.693\n",
            "    2     0.531  0.579\n",
            "Accuracy: 65.32\n",
            "precision total: 0.5775160883770238\n",
            "recall total: 0.6129318169814207\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.0898 - accuracy: 0.4257 - val_loss: 1.0195 - val_accuracy: 0.5754\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0437 - accuracy: 0.4950 - val_loss: 0.8703 - val_accuracy: 0.6171\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9166 - accuracy: 0.6009 - val_loss: 0.8776 - val_accuracy: 0.6071\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8664 - accuracy: 0.6200 - val_loss: 0.9053 - val_accuracy: 0.6111\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8409 - accuracy: 0.6298 - val_loss: 0.8385 - val_accuracy: 0.6508\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8141 - accuracy: 0.6526 - val_loss: 0.8699 - val_accuracy: 0.6409\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7866 - accuracy: 0.6609 - val_loss: 0.8851 - val_accuracy: 0.6329\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7655 - accuracy: 0.6785 - val_loss: 0.8085 - val_accuracy: 0.6468\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7445 - accuracy: 0.6969 - val_loss: 0.8042 - val_accuracy: 0.6627\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7155 - accuracy: 0.7100 - val_loss: 0.7670 - val_accuracy: 0.6687\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7007 - accuracy: 0.7261 - val_loss: 0.8554 - val_accuracy: 0.6270\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6863 - accuracy: 0.7263 - val_loss: 0.8200 - val_accuracy: 0.6488\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6471 - accuracy: 0.7466 - val_loss: 0.8180 - val_accuracy: 0.6488\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6405 - accuracy: 0.7513 - val_loss: 0.8292 - val_accuracy: 0.6349\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6421 - accuracy: 0.7445 - val_loss: 0.9049 - val_accuracy: 0.6329\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6046 - accuracy: 0.7670 - val_loss: 0.9057 - val_accuracy: 0.6369\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6017 - accuracy: 0.7687 - val_loss: 0.8943 - val_accuracy: 0.6687\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5775 - accuracy: 0.7757 - val_loss: 0.8902 - val_accuracy: 0.6885\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5723 - accuracy: 0.7787 - val_loss: 0.9166 - val_accuracy: 0.6706\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5720 - accuracy: 0.7742 - val_loss: 0.9239 - val_accuracy: 0.6806\n",
            "1\n",
            "label precision recall\n",
            "    0     0.371  0.439\n",
            "    1     0.878  0.736\n",
            "    2     0.480  0.713\n",
            "Accuracy: 67.95\n",
            "precision total: 0.5758535631768386\n",
            "recall total: 0.6293839194168513\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.0934 - accuracy: 0.4040 - val_loss: 1.0011 - val_accuracy: 0.7480\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0385 - accuracy: 0.4802 - val_loss: 0.9185 - val_accuracy: 0.6627\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9450 - accuracy: 0.5813 - val_loss: 0.9120 - val_accuracy: 0.6905\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8993 - accuracy: 0.6101 - val_loss: 0.9040 - val_accuracy: 0.6845\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8684 - accuracy: 0.6279 - val_loss: 0.8413 - val_accuracy: 0.6766\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8328 - accuracy: 0.6493 - val_loss: 0.8352 - val_accuracy: 0.6766\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7990 - accuracy: 0.6633 - val_loss: 0.9607 - val_accuracy: 0.5575\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7869 - accuracy: 0.6691 - val_loss: 0.8437 - val_accuracy: 0.6627\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7486 - accuracy: 0.6832 - val_loss: 0.9230 - val_accuracy: 0.6329\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7358 - accuracy: 0.6955 - val_loss: 0.8934 - val_accuracy: 0.6429\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6855 - accuracy: 0.7178 - val_loss: 0.8795 - val_accuracy: 0.6488\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6935 - accuracy: 0.7195 - val_loss: 0.7746 - val_accuracy: 0.7282\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6660 - accuracy: 0.7311 - val_loss: 0.9342 - val_accuracy: 0.6250\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6610 - accuracy: 0.7306 - val_loss: 0.7928 - val_accuracy: 0.7262\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6312 - accuracy: 0.7471 - val_loss: 0.8773 - val_accuracy: 0.6766\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6259 - accuracy: 0.7513 - val_loss: 0.7790 - val_accuracy: 0.7440\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6105 - accuracy: 0.7514 - val_loss: 0.8497 - val_accuracy: 0.7222\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6239 - accuracy: 0.7464 - val_loss: 0.8929 - val_accuracy: 0.6766\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6103 - accuracy: 0.7543 - val_loss: 0.8013 - val_accuracy: 0.7302\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5713 - accuracy: 0.7749 - val_loss: 0.8036 - val_accuracy: 0.7262\n",
            "2\n",
            "label precision recall\n",
            "    0     0.367  0.487\n",
            "    1     0.829  0.744\n",
            "    2     0.497  0.530\n",
            "Accuracy: 66.54\n",
            "precision total: 0.5642767755667879\n",
            "recall total: 0.58709426505557\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.1047 - accuracy: 0.3318 - val_loss: 1.0193 - val_accuracy: 0.7520\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0504 - accuracy: 0.4731 - val_loss: 0.9159 - val_accuracy: 0.6190\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9495 - accuracy: 0.6001 - val_loss: 0.8611 - val_accuracy: 0.6567\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8725 - accuracy: 0.6307 - val_loss: 0.8698 - val_accuracy: 0.6548\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8535 - accuracy: 0.6288 - val_loss: 0.7826 - val_accuracy: 0.6944\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8232 - accuracy: 0.6470 - val_loss: 0.8248 - val_accuracy: 0.6627\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7984 - accuracy: 0.6735 - val_loss: 0.8137 - val_accuracy: 0.6647\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7671 - accuracy: 0.6744 - val_loss: 0.7265 - val_accuracy: 0.7302\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7441 - accuracy: 0.6913 - val_loss: 0.7966 - val_accuracy: 0.6885\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7364 - accuracy: 0.7017 - val_loss: 0.7733 - val_accuracy: 0.7063\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6989 - accuracy: 0.7224 - val_loss: 0.8330 - val_accuracy: 0.6786\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6868 - accuracy: 0.7217 - val_loss: 0.8630 - val_accuracy: 0.6726\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6746 - accuracy: 0.7306 - val_loss: 0.8232 - val_accuracy: 0.6944\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6544 - accuracy: 0.7397 - val_loss: 0.7523 - val_accuracy: 0.7222\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6184 - accuracy: 0.7583 - val_loss: 0.9089 - val_accuracy: 0.6746\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6014 - accuracy: 0.7663 - val_loss: 0.8582 - val_accuracy: 0.6885\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5976 - accuracy: 0.7621 - val_loss: 0.8371 - val_accuracy: 0.7024\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5890 - accuracy: 0.7619 - val_loss: 0.8170 - val_accuracy: 0.7063\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5828 - accuracy: 0.7608 - val_loss: 0.8485 - val_accuracy: 0.7004\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5670 - accuracy: 0.7713 - val_loss: 0.8809 - val_accuracy: 0.6984\n",
            "3\n",
            "label precision recall\n",
            "    0     0.393  0.487\n",
            "    1     0.853  0.813\n",
            "    2     0.507  0.470\n",
            "Accuracy: 70.21\n",
            "precision total: 0.5840829050540276\n",
            "recall total: 0.589741401231573\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.0826 - accuracy: 0.3911 - val_loss: 0.9768 - val_accuracy: 0.6806\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0300 - accuracy: 0.5051 - val_loss: 1.0300 - val_accuracy: 0.5655\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9181 - accuracy: 0.5943 - val_loss: 0.9138 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8671 - accuracy: 0.6194 - val_loss: 0.8780 - val_accuracy: 0.6607\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8299 - accuracy: 0.6449 - val_loss: 0.8929 - val_accuracy: 0.6687\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8016 - accuracy: 0.6684 - val_loss: 0.8901 - val_accuracy: 0.6647\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7676 - accuracy: 0.6765 - val_loss: 0.7970 - val_accuracy: 0.6825\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7340 - accuracy: 0.6823 - val_loss: 0.9522 - val_accuracy: 0.6210\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6853 - accuracy: 0.7170 - val_loss: 0.8757 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6881 - accuracy: 0.7118 - val_loss: 0.8814 - val_accuracy: 0.6647\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6679 - accuracy: 0.7223 - val_loss: 0.9424 - val_accuracy: 0.6687\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6340 - accuracy: 0.7404 - val_loss: 0.9017 - val_accuracy: 0.6806\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6361 - accuracy: 0.7444 - val_loss: 0.9275 - val_accuracy: 0.6607\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6269 - accuracy: 0.7457 - val_loss: 0.8901 - val_accuracy: 0.6925\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6090 - accuracy: 0.7581 - val_loss: 0.9490 - val_accuracy: 0.6746\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5908 - accuracy: 0.7641 - val_loss: 0.9886 - val_accuracy: 0.6071\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5887 - accuracy: 0.7622 - val_loss: 0.9081 - val_accuracy: 0.6925\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5869 - accuracy: 0.7687 - val_loss: 1.0009 - val_accuracy: 0.6329\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5619 - accuracy: 0.7775 - val_loss: 0.9819 - val_accuracy: 0.6806\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5686 - accuracy: 0.7785 - val_loss: 1.0463 - val_accuracy: 0.6250\n",
            "4\n",
            "label precision recall\n",
            "    0     0.316  0.476\n",
            "    1     0.851  0.705\n",
            "    2     0.458  0.530\n",
            "Accuracy: 63.72\n",
            "precision total: 0.5414261460101867\n",
            "recall total: 0.5704398770931652\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.1014 - accuracy: 0.2955 - val_loss: 1.0245 - val_accuracy: 0.7361\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0601 - accuracy: 0.4101 - val_loss: 0.9153 - val_accuracy: 0.6052\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.9550 - accuracy: 0.5927 - val_loss: 0.9060 - val_accuracy: 0.5913\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8937 - accuracy: 0.6148 - val_loss: 0.9108 - val_accuracy: 0.6032\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8573 - accuracy: 0.6117 - val_loss: 0.7847 - val_accuracy: 0.6587\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8134 - accuracy: 0.6313 - val_loss: 0.7606 - val_accuracy: 0.6706\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7787 - accuracy: 0.6516 - val_loss: 0.7592 - val_accuracy: 0.6726\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.7648 - accuracy: 0.6702 - val_loss: 0.7804 - val_accuracy: 0.6687\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7372 - accuracy: 0.6897 - val_loss: 0.7558 - val_accuracy: 0.6825\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6972 - accuracy: 0.7106 - val_loss: 0.8184 - val_accuracy: 0.6806\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6965 - accuracy: 0.7090 - val_loss: 0.8238 - val_accuracy: 0.6944\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6726 - accuracy: 0.7178 - val_loss: 0.8264 - val_accuracy: 0.7183\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6663 - accuracy: 0.7259 - val_loss: 0.8422 - val_accuracy: 0.7321\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6419 - accuracy: 0.7377 - val_loss: 0.9889 - val_accuracy: 0.6964\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6255 - accuracy: 0.7428 - val_loss: 0.8927 - val_accuracy: 0.7123\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6000 - accuracy: 0.7553 - val_loss: 0.9446 - val_accuracy: 0.7143\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5817 - accuracy: 0.7583 - val_loss: 0.9902 - val_accuracy: 0.7103\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5501 - accuracy: 0.7735 - val_loss: 1.0609 - val_accuracy: 0.7004\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5446 - accuracy: 0.7678 - val_loss: 0.9992 - val_accuracy: 0.7183\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5423 - accuracy: 0.7810 - val_loss: 1.0214 - val_accuracy: 0.7044\n",
            "5\n",
            "label precision recall\n",
            "    0     0.331  0.254\n",
            "    1     0.836  0.833\n",
            "    2     0.460  0.591\n",
            "Accuracy: 69.27\n",
            "precision total: 0.5423027715531475\n",
            "recall total: 0.5593539223517611\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.0902 - accuracy: 0.3618 - val_loss: 1.0329 - val_accuracy: 0.6627\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0388 - accuracy: 0.5017 - val_loss: 0.9542 - val_accuracy: 0.6468\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.9112 - accuracy: 0.6167 - val_loss: 0.9088 - val_accuracy: 0.6746\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8705 - accuracy: 0.6411 - val_loss: 0.8524 - val_accuracy: 0.7024\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.8538 - accuracy: 0.6468 - val_loss: 0.8080 - val_accuracy: 0.7520\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8275 - accuracy: 0.6635 - val_loss: 0.8238 - val_accuracy: 0.7083\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7972 - accuracy: 0.6586 - val_loss: 0.7972 - val_accuracy: 0.7262\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7860 - accuracy: 0.6656 - val_loss: 0.8237 - val_accuracy: 0.7183\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7502 - accuracy: 0.6933 - val_loss: 0.7734 - val_accuracy: 0.7123\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7378 - accuracy: 0.6932 - val_loss: 0.8181 - val_accuracy: 0.6944\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7233 - accuracy: 0.6955 - val_loss: 0.7780 - val_accuracy: 0.7004\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6938 - accuracy: 0.7204 - val_loss: 0.7805 - val_accuracy: 0.7063\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6926 - accuracy: 0.7244 - val_loss: 0.7544 - val_accuracy: 0.7163\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6961 - accuracy: 0.7230 - val_loss: 0.8460 - val_accuracy: 0.7063\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6617 - accuracy: 0.7368 - val_loss: 0.7922 - val_accuracy: 0.7202\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6472 - accuracy: 0.7507 - val_loss: 0.8007 - val_accuracy: 0.7262\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6296 - accuracy: 0.7514 - val_loss: 0.8254 - val_accuracy: 0.7103\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6241 - accuracy: 0.7601 - val_loss: 0.8184 - val_accuracy: 0.7222\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6113 - accuracy: 0.7767 - val_loss: 0.7942 - val_accuracy: 0.7421\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5950 - accuracy: 0.7704 - val_loss: 0.8269 - val_accuracy: 0.7321\n",
            "6\n",
            "label precision recall\n",
            "    0     0.354  0.354\n",
            "    1     0.846  0.757\n",
            "    2     0.435  0.634\n",
            "Accuracy: 66.64\n",
            "precision total: 0.5451852492325112\n",
            "recall total: 0.5817748091083482\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 1.0986 - accuracy: 0.3516 - val_loss: 1.0301 - val_accuracy: 0.7183\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 1.0340 - accuracy: 0.4939 - val_loss: 0.8339 - val_accuracy: 0.6567\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.9298 - accuracy: 0.6007 - val_loss: 0.8780 - val_accuracy: 0.6528\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8923 - accuracy: 0.6144 - val_loss: 0.9452 - val_accuracy: 0.6230\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8646 - accuracy: 0.6338 - val_loss: 0.8421 - val_accuracy: 0.6706\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8341 - accuracy: 0.6651 - val_loss: 0.9047 - val_accuracy: 0.6210\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7905 - accuracy: 0.6770 - val_loss: 0.7977 - val_accuracy: 0.6925\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7613 - accuracy: 0.6981 - val_loss: 0.7936 - val_accuracy: 0.6984\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7213 - accuracy: 0.7187 - val_loss: 0.8316 - val_accuracy: 0.7063\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7046 - accuracy: 0.7270 - val_loss: 0.8141 - val_accuracy: 0.7242\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6739 - accuracy: 0.7385 - val_loss: 0.9434 - val_accuracy: 0.6766\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6616 - accuracy: 0.7365 - val_loss: 0.9915 - val_accuracy: 0.6508\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6304 - accuracy: 0.7546 - val_loss: 0.8892 - val_accuracy: 0.7242\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6119 - accuracy: 0.7588 - val_loss: 0.8776 - val_accuracy: 0.7222\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6014 - accuracy: 0.7660 - val_loss: 0.9848 - val_accuracy: 0.6905\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5949 - accuracy: 0.7641 - val_loss: 0.9020 - val_accuracy: 0.7381\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5693 - accuracy: 0.7786 - val_loss: 1.0398 - val_accuracy: 0.6766\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5717 - accuracy: 0.7827 - val_loss: 0.9088 - val_accuracy: 0.7242\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5482 - accuracy: 0.7840 - val_loss: 1.0730 - val_accuracy: 0.6349\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5548 - accuracy: 0.7827 - val_loss: 1.1300 - val_accuracy: 0.6409\n",
            "7\n",
            "label precision recall\n",
            "    0     0.344  0.497\n",
            "    1     0.886  0.667\n",
            "    2     0.387  0.604\n",
            "Accuracy: 62.69\n",
            "precision total: 0.5390074675778531\n",
            "recall total: 0.5892265668688433\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 9ms/step - loss: 1.0897 - accuracy: 0.3319 - val_loss: 0.9794 - val_accuracy: 0.6925\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.0451 - accuracy: 0.4746 - val_loss: 0.8851 - val_accuracy: 0.6290\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9013 - accuracy: 0.6023 - val_loss: 0.8656 - val_accuracy: 0.6429\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8519 - accuracy: 0.6301 - val_loss: 0.9090 - val_accuracy: 0.6032\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8356 - accuracy: 0.6481 - val_loss: 0.8093 - val_accuracy: 0.6905\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8092 - accuracy: 0.6641 - val_loss: 0.8705 - val_accuracy: 0.6230\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7701 - accuracy: 0.6831 - val_loss: 0.8617 - val_accuracy: 0.6548\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.7432 - accuracy: 0.6867 - val_loss: 0.7903 - val_accuracy: 0.7123\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7375 - accuracy: 0.6961 - val_loss: 0.8069 - val_accuracy: 0.7123\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7069 - accuracy: 0.7048 - val_loss: 0.7699 - val_accuracy: 0.7302\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6912 - accuracy: 0.7117 - val_loss: 0.8540 - val_accuracy: 0.6845\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6711 - accuracy: 0.7281 - val_loss: 0.8306 - val_accuracy: 0.7024\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6755 - accuracy: 0.7268 - val_loss: 0.8401 - val_accuracy: 0.7063\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6445 - accuracy: 0.7461 - val_loss: 0.8230 - val_accuracy: 0.7242\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6575 - accuracy: 0.7371 - val_loss: 0.8600 - val_accuracy: 0.7163\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6308 - accuracy: 0.7506 - val_loss: 0.8452 - val_accuracy: 0.7341\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6208 - accuracy: 0.7581 - val_loss: 0.7945 - val_accuracy: 0.7381\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5930 - accuracy: 0.7721 - val_loss: 0.8492 - val_accuracy: 0.7321\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6044 - accuracy: 0.7673 - val_loss: 0.8704 - val_accuracy: 0.7341\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5846 - accuracy: 0.7707 - val_loss: 0.8158 - val_accuracy: 0.7282\n",
            "8\n",
            "label precision recall\n",
            "    0     0.372  0.354\n",
            "    1     0.829  0.799\n",
            "    2     0.467  0.567\n",
            "Accuracy: 68.42\n",
            "precision total: 0.5562519953104261\n",
            "recall total: 0.5734817831401139\n",
            "Epoch 1/20\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 1.0787 - accuracy: 0.4264 - val_loss: 0.8892 - val_accuracy: 0.6964\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9869 - accuracy: 0.5418 - val_loss: 0.8775 - val_accuracy: 0.6329\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.9340 - accuracy: 0.5834 - val_loss: 0.8346 - val_accuracy: 0.6528\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8850 - accuracy: 0.6458 - val_loss: 0.8110 - val_accuracy: 0.6806\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8452 - accuracy: 0.6471 - val_loss: 0.7579 - val_accuracy: 0.7242\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.8210 - accuracy: 0.6470 - val_loss: 0.7728 - val_accuracy: 0.7044\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7993 - accuracy: 0.6506 - val_loss: 0.7316 - val_accuracy: 0.7222\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7695 - accuracy: 0.6613 - val_loss: 0.7301 - val_accuracy: 0.7321\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7685 - accuracy: 0.6772 - val_loss: 0.7326 - val_accuracy: 0.7282\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7407 - accuracy: 0.6931 - val_loss: 0.7625 - val_accuracy: 0.7083\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7343 - accuracy: 0.6955 - val_loss: 0.7023 - val_accuracy: 0.7302\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7215 - accuracy: 0.7002 - val_loss: 0.7272 - val_accuracy: 0.7044\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.7012 - accuracy: 0.7167 - val_loss: 0.7561 - val_accuracy: 0.7063\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6928 - accuracy: 0.7208 - val_loss: 0.7750 - val_accuracy: 0.7143\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6781 - accuracy: 0.7280 - val_loss: 0.7303 - val_accuracy: 0.7242\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6627 - accuracy: 0.7423 - val_loss: 0.7478 - val_accuracy: 0.7123\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.6615 - accuracy: 0.7378 - val_loss: 0.7211 - val_accuracy: 0.7262\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6662 - accuracy: 0.7364 - val_loss: 0.8054 - val_accuracy: 0.7103\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6349 - accuracy: 0.7496 - val_loss: 0.7450 - val_accuracy: 0.7401\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.6276 - accuracy: 0.7608 - val_loss: 0.7778 - val_accuracy: 0.7222\n",
            "9\n",
            "label precision recall\n",
            "    0     0.416  0.434\n",
            "    1     0.862  0.842\n",
            "    2     0.517  0.543\n",
            "Accuracy: 72.37\n",
            "precision total: 0.5985186729615245\n",
            "recall total: 0.6063402491569622\n",
            "\n",
            "Accuracies: 0.6731203019618988\n",
            "Precisions: 0.5624421634820327\n",
            "Recalls: 0.5899768610404609\n",
            "F1-scores: 0.5693983820718918 std: 0.019434819652006743\n",
            "F1-scores micro: 0.6731203007518797 std: 0.028053527331267245\n",
            "Precision class 0: 0.3611744101699625\n",
            "Precision class 1: 0.8523310430496149\n",
            "Precision class 2: 0.47382103722652075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxhqaMEZcpfk"
      },
      "source": [
        "Majority class classifier baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ1lU4r3cvh4",
        "outputId": "ae8204cf-dc5f-4df4-f6a6-5fad7aa88da9"
      },
      "source": [
        "one_pred_dfY=np.ones(len(prediction))\r\n",
        "\r\n",
        "cm = confusion_matrix(ytest, one_pred_dfY, labels=[0, 1, 2])\r\n",
        "\r\n",
        "print(sorted(Counter(one_pred_dfY).items()))\r\n",
        "print(sorted(Counter(ytest).items()))\r\n",
        "\r\n",
        "label=[0,1,2]\r\n",
        "print(\"label precision recall\")\r\n",
        "for label in range(3):\r\n",
        "  print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\r\n",
        "\r\n",
        "print('Accuracy: %.2f' % (accuracy*100))\r\n",
        "print(\"precision total:\", precision_macro_average(cm))\r\n",
        "print(\"recall total:\", recall_macro_average(cm))\r\n",
        "\r\n",
        "accuracies[i]=accuracy\r\n",
        "precisions[i]=precision_macro_average(cm)\r\n",
        "recalls[i]=recall_macro_average(cm)\r\n",
        "\r\n",
        "precision0[i]=precision(0, cm)\r\n",
        "precision1[i]=precision(1, cm)  \r\n",
        "precision2[i]=precision(2, cm)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1.0, 1064)]\n",
            "[(0, 189), (1, 711), (2, 164)]\n",
            "label precision recall\n",
            "    0       nan  0.000\n",
            "    1     0.668  1.000\n",
            "    2       nan  0.000\n",
            "Accuracy: 72.37\n",
            "precision total: nan\n",
            "recall total: 0.3333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}